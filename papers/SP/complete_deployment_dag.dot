digraph "Complete Model Deployment DAG - Ring Attention + Sequence Parallelism on 16 GPUs" {
    rankdir=TB;
    size="60,60";
    
    // Define GPU colors
    node [colorscheme=paired12];
    
    // Subgraph for GPU 0
    subgraph cluster_gpu0 {
        label="GPU 0";
        style=filled;
        color="#FF6B6B20";
        fillcolor="#FF6B6B10";
        
        // Input processing
        input_0 [label="Input Embedding\nX[0] ∈ ℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#FF6B6B"];
        
        // Layer 1 components
        ln1_1_0 [label="LayerNorm 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#FF6B6B"];
        q_proj_1_0 [label="Q Projection (Column)\nW_Q ∈ ℝ^(d_model×d_h×H)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#FF6B6B"];
        k_proj_1_0 [label="K Projection (Column)\nW_K ∈ ℝ^(d_model×d_h×H)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#FF6B6B"];
        v_proj_1_0 [label="V Projection (Column)\nW_V ∈ ℝ^(d_model×d_h×H)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#FF6B6B"];
        
        // Ring Attention stages for GPU 0
        ra_1_0_0 [label="Ring Stage 0\nQ[0]×K[0]×V[0]", shape=diamond, style=filled, fillcolor="#FF6B6B"];
        ra_1_0_1 [label="Ring Stage 1\nQ[0]×K[15]×V[15]", shape=diamond, style=filled, fillcolor="#FF6B6B"];
        ra_1_0_2 [label="Ring Stage 2\nQ[0]×K[14]×V[14]", shape=diamond, style=filled, fillcolor="#FF6B6B"];
        ra_1_0_15 [label="Ring Stage 15\nQ[0]×K[1]×V[1]", shape=diamond, style=filled, fillcolor="#FF6B6B"];
        
        o_proj_1_0 [label="O Projection (Row)\nW_O ∈ ℝ^(d_h×H×d_model)\nℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#FF6B6B"];
        residual1_1_0 [label="Residual 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#FF6B6B"];
        
        // MoE components
        ln2_1_0 [label="LayerNorm 2\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#FF6B6B"];
        router_1_0 [label="Router\nGating Network\nℝ^(B×L/16×8)", shape=hexagon, style=filled, fillcolor="#FF6B6B"];
        gate_1_0 [label="Top-2 Gating\nExpert Selection", shape=pentagon, style=filled, fillcolor="#FF6B6B"];
        
        // 8 Experts
        expert_1_0_0 [label="Expert 0\nW_gate ∈ ℝ^(d_model×4d_model)\nW_up ∈ ℝ^(d_model×4d_model)\nW_down ∈ ℝ^(4d_model×d_model)", shape=box, style=filled, fillcolor="#FF6B6B"];
        expert_1_0_1 [label="Expert 1\nW_gate ∈ ℝ^(d_model×4d_model)\nW_up ∈ ℝ^(d_model×4d_model)\nW_down ∈ ℝ^(4d_model×d_model)", shape=box, style=filled, fillcolor="#FF6B6B"];
        expert_1_0_7 [label="Expert 7\nW_gate ∈ ℝ^(d_model×4d_model)\nW_up ∈ ℝ^(d_model×4d_model)\nW_down ∈ ℝ^(4d_model×d_model)", shape=box, style=filled, fillcolor="#FF6B6B"];
        
        expert_agg_1_0 [label="Expert Aggregation\nWeighted Sum\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#FF6B6B"];
        residual2_1_0 [label="Residual 2\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#FF6B6B"];
    }
    
    // Similar structure for GPU 1-15 (abbreviated for space)
    subgraph cluster_gpu1 {
        label="GPU 1";
        style=filled;
        color="#4ECDC420";
        fillcolor="#4ECDC410";
        
        input_1 [label="Input Embedding\nX[1] ∈ ℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#4ECDC4"];
        
        ln1_1_1 [label="LayerNorm 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#4ECDC4"];
        q_proj_1_1 [label="Q Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#4ECDC4"];
        k_proj_1_1 [label="K Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#4ECDC4"];
        v_proj_1_1 [label="V Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#4ECDC4"];
        
        ra_1_1_0 [label="Ring Stage 0\nQ[1]×K[1]×V[1]", shape=diamond, style=filled, fillcolor="#4ECDC4"];
        ra_1_1_15 [label="Ring Stage 15\nQ[1]×K[2]×V[2]", shape=diamond, style=filled, fillcolor="#4ECDC4"];
        
        o_proj_1_1 [label="O Projection (Row)\nℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#4ECDC4"];
        residual1_1_1 [label="Residual 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#4ECDC4"];
        
        ln2_1_1 [label="LayerNorm 2\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#4ECDC4"];
        router_1_1 [label="Router\nGating Network", shape=hexagon, style=filled, fillcolor="#4ECDC4"];
        gate_1_1 [label="Top-2 Gating", shape=pentagon, style=filled, fillcolor="#4ECDC4"];
        
        expert_1_1_0 [label="Expert 0", shape=box, style=filled, fillcolor="#4ECDC4"];
        expert_1_1_7 [label="Expert 7", shape=box, style=filled, fillcolor="#4ECDC4"];
        
        expert_agg_1_1 [label="Expert Aggregation", shape=ellipse, style=filled, fillcolor="#4ECDC4"];
        residual2_1_1 [label="Residual 2", shape=ellipse, style=filled, fillcolor="#4ECDC4"];
    }
    
    // GPU 15 (last GPU)
    subgraph cluster_gpu15 {
        label="GPU 15";
        style=filled;
        color="#74B9FF20";
        fillcolor="#74B9FF10";
        
        input_15 [label="Input Embedding\nX[15] ∈ ℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#74B9FF"];
        
        ln1_1_15 [label="LayerNorm 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#74B9FF"];
        q_proj_1_15 [label="Q Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#74B9FF"];
        k_proj_1_15 [label="K Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#74B9FF"];
        v_proj_1_15 [label="V Projection (Column)\nℝ^(B×L/16×d_h×H)", shape=box, style=filled, fillcolor="#74B9FF"];
        
        ra_1_15_0 [label="Ring Stage 0\nQ[15]×K[15]×V[15]", shape=diamond, style=filled, fillcolor="#74B9FF"];
        ra_1_15_15 [label="Ring Stage 15\nQ[15]×K[0]×V[0]", shape=diamond, style=filled, fillcolor="#74B9FF"];
        
        o_proj_1_15 [label="O Projection (Row)\nℝ^(B×L/16×d_model)", shape=box, style=filled, fillcolor="#74B9FF"];
        residual1_1_15 [label="Residual 1\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#74B9FF"];
        
        ln2_1_15 [label="LayerNorm 2\nℝ^(B×L/16×d_model)", shape=ellipse, style=filled, fillcolor="#74B9FF"];
        router_1_15 [label="Router\nGating Network", shape=hexagon, style=filled, fillcolor="#74B9FF"];
        gate_1_15 [label="Top-2 Gating", shape=pentagon, style=filled, fillcolor="#74B9FF"];
        
        expert_1_15_0 [label="Expert 0", shape=box, style=filled, fillcolor="#74B9FF"];
        expert_1_15_7 [label="Expert 7", shape=box, style=filled, fillcolor="#74B9FF"];
        
        expert_agg_1_15 [label="Expert Aggregation", shape=ellipse, style=filled, fillcolor="#74B9FF"];
        residual2_1_15 [label="Residual 2", shape=ellipse, style=filled, fillcolor="#74B9FF"];
    }
    
    // Communication edges for Ring Attention
    // KV block transfers between GPUs
    edge [style=dashed, color=blue, constraint=false];
    
    // Ring communication pattern for Layer 1, Stage 1
    k_proj_1_0 -> ra_1_1_1 [label="KV Block\nK/V[0]→GPU1"];
    v_proj_1_0 -> ra_1_1_1;
    k_proj_1_1 -> ra_1_2_1 [label="KV Block\nK/V[1]→GPU2"];
    v_proj_1_1 -> ra_1_2_1;
    // ... continuing pattern
    k_proj_1_14 -> ra_1_15_1 [label="KV Block\nK/V[14]→GPU15"];
    v_proj_1_14 -> ra_1_15_1;
    k_proj_1_15 -> ra_1_0_1 [label="KV Block\nK/V[15]→GPU0"];
    v_proj_1_15 -> ra_1_0_1;
    
    // Data flow connections
    edge [style=solid, color=black, constraint=true];
    
    // Input to Layer 1
    input_0 -> ln1_1_0;
    input_1 -> ln1_1_1;
    input_15 -> ln1_1_15;
    
    // Layer 1 connections for GPU 0
    ln1_1_0 -> q_proj_1_0;
    ln1_1_0 -> k_proj_1_0;
    ln1_1_0 -> v_proj_1_0;
    q_proj_1_0 -> ra_1_0_0;
    k_proj_1_0 -> ra_1_0_0;
    v_proj_1_0 -> ra_1_0_0;
    ra_1_0_0 -> ra_1_0_1;
    ra_1_0_1 -> ra_1_0_2;
    ra_1_0_15 -> o_proj_1_0;
    o_proj_1_0 -> residual1_1_0;
    ln1_1_0 -> residual1_1_0 [style=dotted];
    
    residual1_1_0 -> ln2_1_0;
    ln2_1_0 -> router_1_0;
    router_1_0 -> gate_1_0;
    gate_1_0 -> expert_agg_1_0;
    ln2_1_0 -> expert_1_0_0;
    ln2_1_0 -> expert_1_0_1;
    ln2_1_0 -> expert_1_0_7;
    expert_1_0_0 -> expert_agg_1_0;
    expert_1_0_1 -> expert_agg_1_0;
    expert_1_0_7 -> expert_agg_1_0;
    gate_1_0 -> expert_1_0_0 [style=dotted];
    gate_1_0 -> expert_1_0_1 [style=dotted];
    gate_1_0 -> expert_1_0_7 [style=dotted];
    expert_agg_1_0 -> residual2_1_0;
    ln2_1_0 -> residual2_1_0 [style=dotted];
    
    // Similar connections for other GPUs (abbreviated)
    ln1_1_1 -> q_proj_1_1;
    ln1_1_1 -> k_proj_1_1;
    ln1_1_1 -> v_proj_1_1;
    q_proj_1_1 -> ra_1_1_0;
    k_proj_1_1 -> ra_1_1_0;
    v_proj_1_1 -> ra_1_1_0;
    ra_1_1_15 -> o_proj_1_1;
    o_proj_1_1 -> residual1_1_1;
    
    ln1_1_15 -> q_proj_1_15;
    ln1_1_15 -> k_proj_1_15;
    ln1_1_15 -> v_proj_1_15;
    q_proj_1_15 -> ra_1_15_0;
    k_proj_1_15 -> ra_1_15_0;
    v_proj_1_15 -> ra_1_15_0;
    ra_1_15_15 -> o_proj_1_15;
    o_proj_1_15 -> residual1_1_15;
    
    // Legend
    subgraph cluster_legend {
        label="Tensor Parallelism Legend";
        style=filled;
        color=lightgrey;
        fillcolor=lightgrey;
        
        legend1 [label="Column Parallel\nSplits weight matrix column-wise", shape=box, style=filled, fillcolor=white];
        legend2 [label="Row Parallel\nSplits weight matrix row-wise", shape=box, style=filled, fillcolor=white];
        legend3 [label="Ring Communication\nKV blocks passed in ring", shape=diamond, style=filled, fillcolor=white];
        legend4 [label="Expert Computation\nLocal expert processing", shape=hexagon, style=filled, fillcolor=white];
    }
}